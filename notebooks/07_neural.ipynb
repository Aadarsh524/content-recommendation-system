{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95e069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, random, math\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e049fbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users, n_items: 943 1556\n"
     ]
    }
   ],
   "source": [
    "# Load train/val/test\n",
    "with open(\"../models/train_valid_test.pkl\",\"rb\") as f:\n",
    "    train_df, valid_df, test_df = pickle.load(f)\n",
    "\n",
    "# Build global user and item index (consistent)\n",
    "all_users = sorted(train_df['user_id'].unique())\n",
    "all_items = sorted(train_df['item_id'].unique())\n",
    "user2idx = {u:i for i,u in enumerate(all_users)}\n",
    "item2idx = {it:i for i,it in enumerate(all_items)}\n",
    "n_users, n_items = len(all_users), len(all_items)\n",
    "print(\"n_users, n_items:\", n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8c18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_pos = train_df.groupby(\"user_id\")[\"item_id\"].apply(set).to_dict()\n",
    "\n",
    "def sample_negative(user_id, num_samples=1):\n",
    "    pos = train_user_pos.get(user_id, set())\n",
    "    negs = []\n",
    "    while len(negs) < num_samples:\n",
    "        cand = random.choice(all_items)\n",
    "        if cand not in pos:\n",
    "            negs.append(cand)\n",
    "    return negs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9482c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImplicitPairDataset(Dataset):\n",
    "    # yields (user_idx, pos_item_idx, neg_item_idx) for pairwise or (user, item, label) for pointwise\n",
    "    def __init__(self, interactions_df, num_negatives=4, pointwise=False):\n",
    "        self.interactions = interactions_df.reset_index(drop=True)\n",
    "        self.num_neg = num_negatives\n",
    "        self.pointwise = pointwise\n",
    "        # list of (user,item)\n",
    "        self.user_item_pairs = list(zip(self.interactions['user_id'], self.interactions['item_id']))\n",
    "    def __len__(self):\n",
    "        return len(self.user_item_pairs)\n",
    "    def __getitem__(self, idx):\n",
    "        u, i = self.user_item_pairs[idx]\n",
    "        if self.pointwise:\n",
    "            # return pos examples + sampled negatives as separate rows in training loop (not implemented here)\n",
    "            pass\n",
    "        else:\n",
    "            negs = sample_negative(u, self.num_neg)\n",
    "            return torch.LongTensor([user2idx[u]]), torch.LongTensor([item2idx[i]]), torch.LongTensor([item2idx[negs[0]]])\n",
    "\n",
    "# Quick dataset + dataloader\n",
    "train_dataset = ImplicitPairDataset(train_df, num_negatives=1, pointwise=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, drop_last=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db8c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, emb_dim=64):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(n_items, emb_dim)\n",
    "        self._init_weights()\n",
    "    def _init_weights(self):\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
    "    def forward(self, u, i):\n",
    "        u_e = self.user_emb(u).squeeze(1)    # (B,emb)\n",
    "        i_e = self.item_emb(i).squeeze(1)\n",
    "        dot = (u_e * i_e).sum(dim=1, keepdim=True)  # (B,1)\n",
    "        return dot  # raw score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08473df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, emb_dim=32, mlp_layers=[64,32]):\n",
    "        super().__init__()\n",
    "        # GMF embeddings\n",
    "        self.gmf_user = nn.Embedding(n_users, emb_dim)\n",
    "        self.gmf_item = nn.Embedding(n_items, emb_dim)\n",
    "        # MLP embeddings\n",
    "        self.mlp_user = nn.Embedding(n_users, emb_dim)\n",
    "        self.mlp_item = nn.Embedding(n_items, emb_dim)\n",
    "        # MLP layers\n",
    "        mlp_input = emb_dim * 2\n",
    "        layers = []\n",
    "        for h in mlp_layers:\n",
    "            layers.append(nn.Linear(mlp_input, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            mlp_input = h\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        # final prediction combining GMF and MLP\n",
    "        final_size = emb_dim + (mlp_layers[-1] if len(mlp_layers)>0 else emb_dim)\n",
    "        self.output = nn.Linear(final_size, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self._init_weights()\n",
    "    def _init_weights(self):\n",
    "        nn.init.normal_(self.gmf_user.weight, std=0.01)\n",
    "        nn.init.normal_(self.gmf_item.weight, std=0.01)\n",
    "        nn.init.normal_(self.mlp_user.weight, std=0.01)\n",
    "        nn.init.normal_(self.mlp_item.weight, std=0.01)\n",
    "    def forward(self, u, i):\n",
    "        u = u.squeeze(1); i = i.squeeze(1)\n",
    "        g_u = self.gmf_user(u)\n",
    "        g_i = self.gmf_item(i)\n",
    "        gmf = g_u * g_i  # element-wise\n",
    "        m_u = self.mlp_user(u)\n",
    "        m_i = self.mlp_item(i)\n",
    "        mlp = torch.cat([m_u, m_i], dim=1)\n",
    "        mlp_out = self.mlp(mlp)\n",
    "        x = torch.cat([gmf, mlp_out], dim=1)\n",
    "        out = self.sig(self.output(x)).unsqueeze(1)\n",
    "        return out  # probability score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0f4ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(pos_scores, neg_scores):\n",
    "    # pos_scores, neg_scores: (B,1) raw\n",
    "    x = pos_scores - neg_scores\n",
    "    loss = -torch.log(torch.sigmoid(x) + 1e-8).mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7efc968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "def train_bpr(model, dataloader, optimizer, epochs=3):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for b_u, b_pos, b_neg in tqdm(dataloader):\n",
    "            b_u = b_u.to(device)\n",
    "            b_pos = b_pos.to(device)\n",
    "            b_neg = b_neg.to(device)\n",
    "            # forward pass\n",
    "            pos_scores = model(b_u, b_pos)  # (B,1)\n",
    "            neg_scores = model(b_u, b_neg)\n",
    "            loss = bpr_loss(pos_scores, neg_scores)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs} avg loss: {total_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4464b02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 59/59 [00:00<00:00, 107.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 avg loss: 0.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:00<00:00, 129.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 avg loss: 0.5432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:00<00:00, 122.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 avg loss: 0.4910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:00<00:00, 129.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 avg loss: 0.4896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:00<00:00, 127.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 avg loss: 0.4869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 32\n",
    "mlp_layers = [64,32]\n",
    "ncf = NCF(n_users, n_items, emb_dim=emb_dim, mlp_layers=mlp_layers)\n",
    "opt = torch.optim.Adam(ncf.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "train_bpr(ncf, train_loader, opt, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8edf9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_all_items(model, orig_user_id, topk=10, filter_seen=True):\n",
    "    model.eval()\n",
    "    if orig_user_id not in user2idx:\n",
    "        return []\n",
    "    u_idx = user2idx[orig_user_id]\n",
    "    user_tensor = torch.LongTensor([[u_idx]]).to(device)\n",
    "    # score in batches to avoid OOM\n",
    "    batch = 2048\n",
    "    scores = []\n",
    "    item_indices = list(range(n_items))\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, n_items, batch):\n",
    "            items_batch = item_indices[i:i+batch]\n",
    "            it_tensor = torch.LongTensor([[j] for j in items_batch]).to(device)\n",
    "            u_batch = user_tensor.repeat(len(it_tensor),1)\n",
    "            out = model(u_batch, it_tensor)  # (B,1)\n",
    "            scores.extend(out.squeeze(1).cpu().numpy().tolist())\n",
    "    # map back to original item IDs (all_items list)\n",
    "    scored = list(zip(all_items, scores))\n",
    "    if filter_seen:\n",
    "        seen = train_user_pos.get(orig_user_id, set())\n",
    "        scored = [ (it,sc) for it,sc in scored if it not in seen ]\n",
    "    scored_sorted = sorted(scored, key=lambda x: x[1], reverse=True)[:topk]\n",
    "    return [it for it,sc in scored_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d51864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended, true_items, k=10):\n",
    "    recommended_set = set(recommended[:k]); true_set=set(true_items)\n",
    "    return len(recommended_set & true_set)/k\n",
    "\n",
    "def recall_at_k(recommended, true_items, k=10):\n",
    "    if len(true_items)==0: return 0.0\n",
    "    recommended_set = set(recommended[:k]); true_set=set(true_items)\n",
    "    return len(recommended_set & true_set)/len(true_set)\n",
    "\n",
    "def ndcg_at_k(recommended, true_items, k=10):\n",
    "    dcg = 0.0\n",
    "    for i,item in enumerate(recommended[:k]):\n",
    "        if item in true_items:\n",
    "            dcg += 1.0/math.log2(i+2)\n",
    "    ideal_hits = min(len(true_items), k)\n",
    "    if ideal_hits==0: return 0.0\n",
    "    idcg = sum([1.0/math.log2(i+2) for i in range(ideal_hits)])\n",
    "    return dcg/idcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0f8e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_df(model, df, k=10):\n",
    "    grouped = df.groupby(\"user_id\")[\"item_id\"].apply(list).to_dict()\n",
    "    precs, recs, ndcgs = [], [], []\n",
    "    for u, true_items in grouped.items():\n",
    "        preds = score_all_items(model, u, topk=k, filter_seen=True)\n",
    "        precs.append(precision_at_k(preds, true_items, k))\n",
    "        recs.append(recall_at_k(preds, true_items, k))\n",
    "        ndcgs.append(ndcg_at_k(preds, true_items, k))\n",
    "    return {\"precision@\"+str(k):np.mean(precs), \"recall@\"+str(k):np.mean(recs), \"ndcg@\"+str(k):np.mean(ndcgs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c12dd39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NCF on validation (this may take a while)...\n",
      "NCF validation metrics: {'precision@10': 0.0706256627783669, 'recall@10': 0.06430795008904644, 'ndcg@10': 0.07953139710253686}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Evaluating NCF on validation (this may take a while)...\")\n",
    "metrics_ncf = evaluate_model_on_df(ncf, valid_df, k=10)\n",
    "print(\"NCF validation metrics:\", metrics_ncf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95abd7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ncf.state_dict(), \"../models/ncf_state.pt\")\n",
    "with open(\"../models/ncf_meta.pkl\",\"wb\") as f:\n",
    "    pickle.dump({\"user2idx\":user2idx, \"item2idx\":item2idx, \"all_users\":all_users, \"all_items\":all_items}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51dfd471",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_emb = ncf.gmf_item.weight.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f2c4362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# item embedding matrix (n_items, emb_dim)\n",
    "item_vecs = ncf.gmf_item.weight.detach().cpu().numpy()\n",
    "\n",
    "# Normalize for fast cosine similarity\n",
    "item_norm = item_vecs / np.linalg.norm(item_vecs, axis=1, keepdims=True)\n",
    "\n",
    "def topk_similar_items(target_item_id, k=10):\n",
    "    if target_item_id not in item2idx:\n",
    "        return []\n",
    "    idx = item2idx[target_item_id]\n",
    "    v = item_norm[idx]                      # (emb_dim,)\n",
    "    sims = item_norm @ v                    # (n_items,)\n",
    "    # sort by similarity\n",
    "    top_idx = np.argpartition(-sims, range(k+1))[:k+1]\n",
    "    top_idx = top_idx[top_idx != idx]       # exclude itself\n",
    "    top = sorted(top_idx, key=lambda x: sims[x], reverse=True)[:k]\n",
    "    return [all_items[i] for i in top]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99cc675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_for_user(user_id, num_items=200):\n",
    "    # Step 1: get items user has interacted with\n",
    "    seen = list(train_user_pos.get(user_id, []))\n",
    "    if len(seen) == 0:\n",
    "        return random.sample(all_items, num_items)\n",
    "\n",
    "    # Step 2: for each seen item → get similar items\n",
    "    cand = []\n",
    "    for it in seen:\n",
    "        sim_items = topk_similar_items(it, k=20)\n",
    "        cand.extend(sim_items)\n",
    "\n",
    "    # Step 3: remove seen items\n",
    "    cand = list(set(cand) - set(seen))\n",
    "\n",
    "    # Step 4: sample up to num_items\n",
    "    if len(cand) > num_items:\n",
    "        cand = random.sample(cand, num_items)\n",
    "\n",
    "    return cand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cdbda2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import os\n",
    "\n",
    "emb_dim = item_vecs.shape[1]\n",
    "ann = AnnoyIndex(emb_dim, 'angular')\n",
    "\n",
    "for i in range(n_items):\n",
    "    ann.add_item(i, item_vecs[i])\n",
    "\n",
    "ann.build(20)\n",
    "ann.save(\"../models/item_annoy.idx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f902c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = AnnoyIndex(emb_dim, 'angular')\n",
    "ann.load(\"../models/item_annoy.idx\")\n",
    "\n",
    "def annoy_similar_items(item_id, k=10):\n",
    "    idx = item2idx[item_id]\n",
    "    top = ann.get_nns_by_item(idx, k+1)[1:]   # exclude itself\n",
    "    return [all_items[i] for i in top]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eff81cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = generate_candidates_for_user('166', num_items=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f399188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_candidates(user_id, candidates, topk=10):\n",
    "    ncf.eval()\n",
    "    u_idx = user2idx.get(user_id)\n",
    "    if u_idx is None:\n",
    "        return []\n",
    "    \n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for it in candidates:\n",
    "            it_idx = item2idx[it]\n",
    "            u_tensor = torch.LongTensor([[u_idx]]).to(device)\n",
    "            i_tensor = torch.LongTensor([[it_idx]]).to(device)\n",
    "            s = ncf(u_tensor, i_tensor).item()\n",
    "            scores.append((it, s))\n",
    "    \n",
    "    ranked = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    return [it for it,_ in ranked[:topk]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b567b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline(df, k=10):\n",
    "    grouped = df.groupby(\"user_id\")[\"item_id\"].apply(list).to_dict()\n",
    "    precs, recs, ndcgs = [], [], []\n",
    "\n",
    "    for user, true_items in grouped.items():\n",
    "        cand = generate_candidates_for_user(user, num_items=200)\n",
    "        preds = rank_candidates(user, cand, topk=k)\n",
    "\n",
    "        precs.append(precision_at_k(preds, true_items, k))\n",
    "        recs.append(recall_at_k(preds, true_items, k))\n",
    "        ndcgs.append(ndcg_at_k(preds, true_items, k))\n",
    "\n",
    "    print(\"End-to-End Results:\")\n",
    "    print(\"Precision@{}: {:.4f}\".format(k, np.mean(precs)))\n",
    "    print(\"Recall@{}: {:.4f}\".format(k, np.mean(recs)))\n",
    "    print(\"NDCG@{}: {:.4f}\".format(k, np.mean(ndcgs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c77650f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End-to-End Results:\n",
      "Precision@10: 0.0680\n",
      "Recall@10: 0.0386\n",
      "NDCG@10: 0.0743\n"
     ]
    }
   ],
   "source": [
    "evaluate_pipeline(valid_df, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acf5f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/item_vecs.npy\", \"wb\") as f:\n",
    "    np.save(f, item_vecs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
